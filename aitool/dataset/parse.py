import numpy as np
import tqdm
from pycocotools.coco import COCO
import pycocotools.mask as maskUtils

import mmcv
import aitool


class PklParserBase():
    """parse the pkl file (generated by mmdetection)
    """
    def __init__(self,
                 pkl_file,
                 ann_file,
                 keep_boundary=True,
                 score_threshold=0.05,
                 min_area=10):
        self.keep_boundary = keep_boundary
        self.score_threshold = score_threshold
        self.min_area = min_area

        if isinstance(pkl_file, str):
            results = mmcv.load(pkl_file)
        elif isinstance(pkl_file, (list, tuple)):
            results = pkl_file
        else:
            raise TypeError(f'do not support the pkl file type: {type(pkl_file)}')

        coco = COCO(ann_file)
        self.img_ids = coco.get_img_ids()
        self.cat_ids = coco.get_cat_ids()
        self.img_fns = []
        self.img_sizes = []

        print("begin to convert pkl file to specific format")
        self.objects = dict()
        for idx, img_id in tqdm.tqdm(enumerate(self.img_ids)):
            info = coco.load_imgs([img_id])[0]
            img_name = aitool.get_basename(info['file_name'])
            img_size = (info['height'], info['width'])
            self.img_fns.append(img_name)
            result = results[idx]

            self.objects[img_name] = self._convert_items(result, img_size=img_size)

    def _convert_items(self, result, img_size=(1024, 1024)):
        """convert the result (single image) in pkl file to specific format (default: Faster R-CNN, bbox) 

        Args:
            result (tuple): detection result of single image
            img_size (tuple): image size (height, width)

        Return:
            list: converted objects
        """
        objects = []

        for label in range(len(result)):
            bboxes = result[label]
            for i in range(bboxes.shape[0]):
                data = dict()
                data['bbox'] = aitool.xyxy2xywh(bboxes[i][:4])
                if data['bbox'][2] * data['bbox'][3] < self.min_area:
                    continue
                data['score'] = float(bboxes[i][4])
                if data['score'] < self.score_threshold:
                    continue
                data['category_id'] = self.cat_ids[label]
                objects.append(data)

        return objects

    def __call__(self, image_fn):
        if image_fn in self.objects.keys():
            return self.objects[image_fn]
        else:
            print("{} is not in pkl".format(image_fn))
            return []


class PklParserMask(PklParserBase):
    def _convert_items(self, result, img_size=(1024, 1024)):
        """convert the result (single image) in pkl file to specific format (Mask R-CNN, bbox + mask) 

        Args:
            result (tuple): detection result of single image
            img_size (tuple): image size (height, width)

        Return:
            list: converted objects
        """
        objects = []

        det, seg = result
        for label in range(len(det)):
            bboxes = det[label]
            if isinstance(seg, tuple):
                segms = seg[0][label]
            else:
                segms = seg[label]

            for i in range(bboxes.shape[0]):
                data = dict()
                data['bbox'] = aitool.xyxy2xywh(bboxes[i][:4])
                if data['bbox'][2] * data['bbox'][3] < self.min_area:
                    continue
                data['score'] = float(bboxes[i][4])
                if data['score'] < self.score_threshold:
                    continue
                data['category_id'] = self.cat_ids[label]
                if isinstance(segms[i]['counts'], bytes):
                    segms[i]['counts'] = segms[i]['counts'].decode()
                data['segmentation'] = segms[i]
                data['pointobb'] = aitool.bbox2pointobb(bboxes[i][:4])
                objects.append(data)

        return objects


class PklParserMaskOBB(PklParserBase):
    def _convert_items(self, result, img_size=(1024, 1024)):
        """convert the result (single image) in pkl file to specific format (Mask OBB, bbox + maskobb) 

        Args:
            result (tuple): detection result of single image
            img_size (tuple): image size (height, width)

        Return:
            list: converted objects
        """
        objects = []

        det, seg = result
        for label in range(len(det)):
            bboxes = det[label]
            if isinstance(seg, tuple):
                segms = seg[0][label]
            else:
                segms = seg[label]

            for i in range(bboxes.shape[0]):
                data = dict()
                data['bbox'] = aitool.xyxy2xywh(bboxes[i][:4])
                data['score'] = float(bboxes[i][4])
                if data['score'] < self.score_threshold:
                    continue
                data['category_id'] = self.cat_ids[label]
                if isinstance(segms[i]['counts'], bytes):
                    segms[i]['counts'] = segms[i]['counts'].decode()
                data['segmentation'] = segms[i]
                thetaobb, pointobb = aitool.segm2rbbox(segms[i])
                data['pointobb'] = pointobb
                data['thetaobb'] = thetaobb
                if thetaobb[2] * thetaobb[3] < self.min_area:
                    continue
                if not self.keep_boundary:
                    cx_flag = thetaobb[0] < 0 or thetaobb[0] > img_size[1] - 1
                    cy_flag = thetaobb[1] < 0 or thetaobb[1] > img_size[0] - 1
                    if cx_flag or cy_flag:
                        continue
                objects.append(data)

        return objects


class COCOParser():
    def __init__(self, 
                 ann_file, 
                 classes=[''],
                 data_keys=['bbox', 'category_id', 'segmentation']):
        """parse coco annotation file

        Args:
            ann_file (str): coco annotation file
            classes (list, optional): class ids. Defaults to [''].
            data_keys (list, optional): parse which items. Defaults to ['bbox', 'category_id', 'segmentation'].
        """
        self.data_keys = data_keys
        self.coco = COCO(ann_file)
        self.img_ids = self.coco.get_img_ids()
        self.cat_ids = self.coco.get_cat_ids()
        self.categories = self.coco.dataset['categories']
        self.img_fns = []

        print("begin to parse the coco annotation file")
        self.objects = dict()
        for img_id in tqdm.tqdm(self.img_ids):
            img_info = self.coco.load_imgs([img_id])[0]
            img_name = aitool.get_basename(img_info['file_name'])
            self.img_fns.append(img_name)

            ann_ids = self.coco.get_ann_ids(img_ids=[img_id])
            ann_info = self.coco.load_anns(ann_ids)
            self.objects[img_name] = self._convert_items(ann_info, img_info)
    
    def _convert_items(self, ann_info, img_info):
        objects = []

        img_height, img_width = img_info['height'], img_info['width']
        for ann in ann_info:
            data = dict()
            for data_key in self.data_keys:
                if data_key in ann:
                    data[data_key] = ann[data_key]
                else:
                    raise RuntimeError(f'coco ann file does not contain {data_key}')

            data['img_height'], data['img_width'] = img_height, img_width
            
            objects.append(data)

        return objects

    def __call__(self, image_fn):
        if image_fn in self.objects.keys():
            return self.objects[image_fn]
        else:
            print("{} is not in coco file".format(image_fn))
            return []